\section{Introduction}

Key value grouping operation, known as GROUP BY clause, is a key operation in database systems \cite{gray1997data}, \cite{stephens2005oracle}, \cite{mysql2009mysql}, \cite{momjian2001postgresql}. It groups a set of out-of-order records into multiple groups according to a certain key. GroupBy operation is often used with aggregate functions which produces a single row of summary information for each group, e.g., GroupBy-Aggregate in SQL. GroupBy is also widely used in distributed computing frameworks for distributing and locating the data. MapReduce \cite{dean2008mapreduce} expresses the computational process as three phases: Map, Shuffle and Reduce. During the shuffle phase, the key-value pairs that have the same key are aggregated together to form a Map output file, and they are sent to the same Reduce processor where the final cluster-wide aggregation (reduction) is applied on them. The efficiency of the key-value grouping step is crucial to both relational databases and distributed computing systems.


%Another popular use case for key grouping is to accumulate state across the stream in distributed stream processing engines (DSPEs) such as Storm \cite{storm2013storm}, S4 \cite{neumeyer2010s4}, Smaza \cite{noghabi2017samza}. This grouping in DSPEs is usually implemented by partitioning the stream on a key \cite{nasir2015power}. The strategies that are used to route tuples in a stream toward available operators can be divided into two categories: key grouping for stateful operators where a stream of tuples is partitioned in several disjoint sub-streams depending on the values contained \cite{rivetti2015efficient} and shuffle grouping for stateless operators where each tuple of a stream can be randomly assigned to any available operator \cite{Rivetti2016Online}. However, all the above works are focused on how to route kv-pairs to available operators for alleviating load imbalance but ignoring local key value aggregation overhead at the receiver side. In fact, the execution time depends on not only stream partition but also local aggregation. Our work will focus on accelerating the local GroupBy aggregation in this paper.

There are two categories of GroupBy implementations in general, sort-based grouping and hash-based grouping. Basically, the \emph{sort-based grouping} makes the data records sorted in the order of the group key, so that the records with the same group key are located together. While the \emph{hash-based grouping} typically hashes key-value pairs to a hash table structure where multiple key-value pairs in the same group (sharing the same group key) are stored in the same bucket.

Recall that key-value pairs (kv-pairs) grouping operation is the key operation in Hadoop MapReduce \cite{dean2008mapreduce}. The map output kv-pairs are locally grouped by keys before they are shuffled to reduce workers. These map output kv-pairs (i.e., reduce input kv-pairs) from various map workers are further merged to obtain a global grouped kv-pairs. Each group of kv-pairs sharing the same key is the input of a reduce function. In Hadoop Mapreduce implementation, a kind of sort-based grouping, \emph{merge-sort grouping}, is used, which can perform quite general grouping tasks at scale even in the absence of available memory. However, merge-sort grouping involves large amount of redundant computation and I/Os. The previous work \cite{shvachko2010hadoop,yu2009distributed,Li2011A} shows that merge-sort grouping adopted by Hadoop is found to be among the worst-performing choices.

For many applications, hash-based grouping improves performance because these applications require only unsorted grouping \cite{lin2011tenzing}, \cite{yu2009distributed}. However, hash-based grouping consumes more memory than sort-based grouping because it requires to load all records into memory. The performance heavily depends on the amount of available memory. A hash-based grouping has been used in MariaDB \cite{bartholomew2012mariadb}, Oracle \cite{stephens2005oracle}, Postgresql \cite{momjian2001postgresql}, and SQL Server \cite{agrawal2005database}. The hash-based grouping creates an in-memory hash table for grouping rows. If the hash table becomes too large to be fit in memory, the input records are partitioned into smaller work tables which are recursively partitioned until they fit into memory. Once all input groups have been processed, the completed in-memory groups are output and repeat the algorithm by reading back and aggregating one spilled partition at a time until all partitions have been processed. We refer to this approach as \emph{memory-constraint hash grouping}. It excels at efficiently aggregating large data sets and performs better than merge-sort grouping in some situation.

As known, in real life, the group sizes in many data sets follow power-law distributions \cite{MEJPower}, the big group sizes and small group sizes vary over an enormous range. When these data sets are processed by memory-constrain hash grouping in limited memory, the sub-tables sizes are not balanced caused by big groups, which leads to multiple recursive partitions and downgrade grouping performance. The performance reduction resulting from power-law distributions often occurs in various applications, we observe that these implementations exhibit different performance and memory usage for big groups and small groups. As shown in Figure \ref{fig:paretoBig}, the \emph{indexing and filling} method performs best compared with merge-sort and memory-constraint hash grouping when grouping the big groups. Indexing and filling method proposed in this article is a file filling process according to an index, it creates an in-memory offset index which records each group's output position in result file firstly and fills the result file on the basis of the offset index, so the best grouping approach is indexing and filling for big groups. As shown in Figure \ref{fig:paretoSmall}, the \emph{partitioned hash grouping} method runs faster in limited memory when grouping small groups, that the kv-pairs in small groups are processed partition by partition is refered as partitioned hash grouping, so grouping small groups by partitioned hash is the best choice. Therefore, the ideal implementation should take the group size into account, and a hybrid grouping approach is desired.

\begin{figure}[htbp]%figure 2
\subfloat[Performance comparison on big groups]{\includegraphics[width = 1.68in]{fig/paretoBig.eps}\label{fig:paretoBig}}
    \hspace{0.23cm}
    \subfloat[Performance comparison on small groups]{\includegraphics[width =1.68in]{fig/paretoSmall.eps}\label{fig:paretoSmall}}\\
%\includegraphics[width=.5\textwidth]{fig/pareto_index_hash}
\caption{Performance comparison of big groups and small groups. The big groups and small groups are selected from a simulation data set Pareto, the group sizes of Pareto follow a power-law distribution.}
\label{fig: big and small}
\end{figure}


Based on this observation, we propose an I/O efficient hash grouping scheme \emph{power-law hash} that leverages power-law distributions and hashing in this paper, the big groups and small groups are processed separately in the algorithm, they are grouped by indexing-filling method and partitioned hash grouping approach. But there is a problem raised, how to distinguish between big groups and small groups efficiently? We solve it by leveraging the count-min sketch\cite{Cormode2009Count} and power-law distributions, the big groups and small groups are judged by their rough group size counted by the count-min sketch, the basis of judgment is Pareto principle\cite{MEJPower} --- a application of power-law distributions.

The whole process of key grouping by power-law hash can avoid unnecessary repeat access to disk and needs less memory. When dealing with the big groups, the kv-pairs in big groups are written to the result file directly on the basis of offset index, only the offset index is stored in memory during the grouping process of big groups, the offset index size is much less than the big groups sizes and there is no need to load any whole group into memory, so the writing back to disk caused by out-of-memory can be prevented and the I/O cost can be reduced. For a data set whose group sizes follow a power-law distribution, the majority of the data set has been written to the result file after dealing with the big groups. So partition unbalance can be avoided to a great extent because there is no big groups in the remaining data set when we partition the small groups, and then it can prevent multiple recursive division to the big partitions.

Our main contributions can be summarized as follows:

\begin{list}{\labelitemi}{\setlength{\leftmargin}{5mm}\setlength{\itemindent}{0mm}
\setlength{\topsep}{0.5mm}\setlength{\itemsep}{2mm}\setlength{\parsep}{0mm}}
\item Firstly, we study the problem of key grouping in modern distributed processing engines and traditional relation databases.
\item Secondly, we present an I/O efficient hash grouping scheme that leverages the power-law distributions and hashing, which can complete the key grouping operation with less memory usage and time cost.
\item Thirdly, we evaluate our algorithm through extensive experiments. The results show that power-law hash improves the performance with the same limited memory usage compared to memory-constraint hash, the runntime gap is greater compared to merge-sort.
\end{list}


The rest of this paper is organized as follows. Section \uppercase\expandafter{\romannumeral2} describes the related work. In Section \uppercase\expandafter{\romannumeral3}, we propose our grouping method power-law hash and present the key optimizations. Section \uppercase\expandafter{\romannumeral4} discusses the parameters setting. The experimental results are presented in Section \uppercase\expandafter{\romannumeral5}. Finally, Section \uppercase\expandafter{\romannumeral6} concludes the paper.

