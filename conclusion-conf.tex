\section{Conclusions}

Grouping key value pairs are essential for many practical applications that include MapReduce, SQL Hash Group By, etc. The volume of such data increases rapidly, therefore, it is essential to improve fast key value grouping methods. In this paper we proposed bHash, a method that supports very long records, large data sets and works efficiently even if the data distribution is skewed  and is easily implemented. Extensive experimental evaluation with real data sets revealed that our method is much more efficient than existing ones in terms of speed and computational resources. bHash performs 20\%~57.8\% times faster than merge-sort and faster than memory-constraint hash up to 45\% times in condition of using the same memory. For the long-tailed distributions such as Pareto, our algorithm even achieves 50\% better overall performance than merge-sort but occupies 40\% times less memory and 45\% faster than memory-constraint hash in the case of using 39\% times less memory. Our method can save memory up to from two to six times compared memory-constraint hash and performs well both in time performance and memory consumption.

This work is part of a large project that aims to develop an engine for grouping and processing of massive data. We are currently working on scaling our method to the distributed computing framework. As we know, stand-alone aggregating key value pairs of different groups is applied to both map phase and reduce phase in MapReduce independently. So bHash is easily parallelizable. We are also focusing on the parallel processing various types of grouping using the bHash.

